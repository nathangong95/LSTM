{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13494, 1, 14)\n",
      "13494\n",
      "(13494, 1, 14)\n",
      "13494\n",
      "(13495, 1, 14)\n",
      "13495\n",
      "(13497, 1, 14)\n",
      "13497\n",
      "(13497, 1, 14)\n",
      "13497\n",
      "(13496, 1, 14)\n",
      "13496\n",
      "(13497, 1, 14)\n",
      "13497\n",
      "13494\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as spio\n",
    "import numpy as np\n",
    "import keras.utils\n",
    "from keras import utils as np_utils\n",
    "from keras.utils import to_categorical\n",
    "import h5py\n",
    "import pandas as pd\n",
    "Data = spio.loadmat('Folder.mat', squeeze_me=True,struct_as_record=True)\n",
    "train_data=[]\n",
    "train_data.append(Data['Folder1'])\n",
    "train_data.append(Data['Folder2'])\n",
    "train_data.append(Data['Folder3'])\n",
    "train_data.append(Data['Folder4'])\n",
    "train_data.append(Data['Folder5'])\n",
    "train_data.append(Data['Folder6'])\n",
    "train_data.append(Data['Folder7'])\n",
    "train_label=np.load('train_label.npy')\n",
    "for i in range(7):\n",
    "    _,_,s=train_data[i].shape\n",
    "    train_data[i]=np.reshape(train_data[i],(14,s))\n",
    "    train_data[i]=train_data[i].T\n",
    "    train_data[i]=np.reshape(train_data[i],(s,1,14))\n",
    "    print(train_data[i].shape)\n",
    "    print(len(train_label[i]))\n",
    "for i in range(7):\n",
    "    train_label[i]=to_categorical(train_label[i])\n",
    "f=[]\n",
    "f.append(h5py.File('t1.mat'))\n",
    "f.append(h5py.File('t2.mat'))\n",
    "f.append(h5py.File('t3.mat'))\n",
    "f.append(h5py.File('t4.mat'))\n",
    "f.append(h5py.File('t5.mat'))\n",
    "f.append(h5py.File('t6.mat'))\n",
    "f.append(h5py.File('t7.mat'))\n",
    "print(len(f[0]['color']['kT'][0]))#430874.548060"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_vector(vector):\n",
    "    \"\"\" Returns the unit vector of the vector.  \"\"\"\n",
    "    return vector / np.linalg.norm(vector)\n",
    "\n",
    "def angle_between(v1, v2):\n",
    "    \"\"\" Returns the angle in radians between vectors 'v1' and 'v2'::\n",
    "\n",
    "            >>> angle_between((1, 0, 0), (0, 1, 0))\n",
    "            1.5707963267948966\n",
    "            >>> angle_between((1, 0, 0), (1, 0, 0))\n",
    "            0.0\n",
    "            >>> angle_between((1, 0, 0), (-1, 0, 0))\n",
    "            3.141592653589793\n",
    "    \"\"\"\n",
    "    v1_u = unit_vector(v1)\n",
    "    v2_u = unit_vector(v2)\n",
    "    return np.arccos(np.clip(np.dot(v1_u, v2_u), -1.0, 1.0))\n",
    "def addFeature(Data):\n",
    "    s,a=Data.shape\n",
    "    newData=np.zeros((s,22))\n",
    "    newData[:,:14]=Data\n",
    "    for i in range(s):\n",
    "        newData[i,14]=((Data[i,2]-Data[i,6])**2+(Data[i,3]-Data[i,7])**2)**0.5\n",
    "        newData[i,15]=((Data[i,4]-Data[i,8])**2+(Data[i,5]-Data[i,9])**2)**0.5\n",
    "        newData[i,16]=((Data[i,6]-Data[i,10])**2+(Data[i,7]-Data[i,11])**2)**0.5\n",
    "        newData[i,17]=((Data[i,8]-Data[i,12])**2+(Data[i,9]-Data[i,13])**2)**0.5\n",
    "        v1=[Data[i,6]-Data[i,2],Data[i,7]-Data[i,3]]\n",
    "        v2=[Data[i,10]-Data[i,6],Data[i,11]-Data[i,7]]\n",
    "        newData[i,18]=angle_between(v1,v2)\n",
    "\n",
    "        v1=[Data[i,8]-Data[i,4],Data[i,9]-Data[i,5]]\n",
    "        v2=[Data[i,12]-Data[i,8],Data[i,13]-Data[i,9]]\n",
    "        newData[i,19]=angle_between(v1,v2)\n",
    "\n",
    "        newData[i,20]=0\n",
    "        newData[i,21]=0\n",
    "    return newData\n",
    "test=np.reshape(train_data[0],(13494,14))\n",
    "print(test)\n",
    "test=addFeature(test)\n",
    "print(test[:,:14])\n",
    "#print(angle_between([1,0],[-1,-1]))\n",
    "#print(angle_between([1,0],[-1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\", font_scale=2.0)\n",
    "def trainLSTM(train_data,train_label,Hidden_unit,batch_s):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(Hidden_unit, input_shape=(1, 14)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4,activation='sigmoid'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "    for i in range(len(train_data)):\n",
    "        model.fit(train_data[i],train_label[i], batch_size=batch_s, epochs=10)\n",
    "    return model\n",
    "\n",
    "## Add path to custom libraries\n",
    "#module_path = '/home/kali/pgabriel-dev/thesis/scripts/python/'\n",
    "#if module_path not in sys.path:\n",
    "#    sys.path.append(module_path)  \n",
    "#    \n",
    "## Add custom libraries\n",
    "#from pyFreeBe.utils import load, libviz\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Greys):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "#    sns.set_context(\"paper\", font_scale=2)\n",
    "    sns.set(font_scale=2)\n",
    "\n",
    "    fig, ax = plt.subplots(1)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 fontsize=24,\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    ax.grid(False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return fig\n",
    "def toIntegerLabel(l):\n",
    "    label=[]\n",
    "    s,_=l.shape\n",
    "    for i in range(s):\n",
    "        label.append(l[i].tolist().index(max(l[i].tolist())))\n",
    "    return label\n",
    "def toOnOffSet(integerLabel):\n",
    "    onoff=[]\n",
    "    lmsk = [(el==1) or (el==3) for el in integerLabel]\n",
    "    Rmsk = [(el==2) or (el==3) for el in integerLabel]\n",
    "    i=0\n",
    "    while i<len(lmsk):\n",
    "        if lmsk[i]:\n",
    "            temp=[]\n",
    "            temp.append('l')\n",
    "            temp.append(i)\n",
    "            for j in range(i,len(lmsk)):\n",
    "                if not lmsk[j]:\n",
    "                    temp.append(j-1)\n",
    "                    onoff.append(temp)\n",
    "                    i=j\n",
    "                    break\n",
    "        i+=1\n",
    "    i=0\n",
    "    while i<len(Rmsk):\n",
    "        if Rmsk[i]:\n",
    "            temp=[]\n",
    "            temp.append('r')\n",
    "            temp.append(i)\n",
    "            for j in range(i,len(Rmsk)):\n",
    "                if not Rmsk[j]:\n",
    "                    temp.append(j-1)\n",
    "                    onoff.append(temp)\n",
    "                    i=j\n",
    "                    break\n",
    "        i+=1\n",
    "    return onoff\n",
    "def toPanda_test(model,train_data,whichFolder,f):\n",
    "    #print(whichFolder)\n",
    "    #print(model.predict(train_data[whichFolder]))\n",
    "    IntegerLabel=toIntegerLabel(model.predict(train_data[whichFolder]))\n",
    "    OnOff=toOnOffSet(IntegerLabel)\n",
    "    df=[]\n",
    "    for i in range(len(OnOff)):\n",
    "        OnOff[i][1]=f[whichFolder]['color']['kT'][0][OnOff[i][1]]/1000\n",
    "        OnOff[i][2]=f[whichFolder]['color']['kT'][0][OnOff[i][2]]/1000\n",
    "        df.append(pd.DataFrame(data={'onset':[OnOff[i][1]],  'offset':[OnOff[i][2]],  'label':[OnOff[i][0]]}))\n",
    "    df = pd.concat(df, axis=0)\n",
    "    df.sort_values(by=('onset'), inplace=True)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    return df\n",
    "def toPanda_train(train_label,whichFolder,f):\n",
    "    IntegerLabel=toIntegerLabel(train_label[whichFolder])\n",
    "    OnOff=toOnOffSet(IntegerLabel)\n",
    "    df=[]\n",
    "    for i in range(len(OnOff)):\n",
    "        OnOff[i][1]=f[whichFolder]['color']['kT'][0][OnOff[i][1]]/1000\n",
    "        OnOff[i][2]=f[whichFolder]['color']['kT'][0][OnOff[i][2]]/1000\n",
    "        df.append(pd.DataFrame(data={'onset':[OnOff[i][1]],  'offset':[OnOff[i][2]],  'label':[OnOff[i][0]]}))\n",
    "    df = pd.concat(df, axis=0)\n",
    "    df.sort_values(by=('onset'), inplace=True)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    return df\n",
    "#print(toPanda_test(model,train_data,0,f))\n",
    "#print(toPanda_train(train_label,0,f))\n",
    "def score_periods(df_manual, df_pred, params=None, err1thresh=2, err2thresh=5):\n",
    "    \n",
    "    # initialize storage variables/arrays\n",
    "    err1 = np.empty(len(df_manual)) # err1\n",
    "    err2 = np.empty(len(df_manual)) # err2\n",
    "    detected = np.zeros(len(df_manual), dtype=bool) # detected\n",
    "    \n",
    "    # Loop through each manual\n",
    "    for i, (label, offset, onset) in df_manual.iterrows():\n",
    "                \n",
    "        # search for nearest neighbor in df_pred\n",
    "        pred_onsets = df_pred['onset'].values\n",
    "        pred_offsets = df_pred['offset'].values\n",
    "        \n",
    "        i_onset_match = np.argmin(np.abs(pred_onsets-onset))\n",
    "        i_offset_match = np.argmin(np.abs(pred_offsets - offset))\n",
    "        \n",
    "        if label=='b' or i_onset_match != i_offset_match:\n",
    "            err1[i] = np.nan\n",
    "            err2[i] = np.nan\n",
    "            detected[i] = False\n",
    "            continue\n",
    "        \n",
    "        # calculate onset and offset error (err1, err2)\n",
    "        err1[i] = onset - pred_onsets[i_onset_match]\n",
    "        err2[i] = offset - pred_offsets[i_offset_match]\n",
    "        if np.abs(err1[i])>err1thresh or np.abs(err2[i])>err2thresh:\n",
    "            detected[i] = False\n",
    "        else:\n",
    "            detected[i]=True\n",
    "\n",
    "    df_return = df_manual.copy()\n",
    "    df_return['err1'] = err1\n",
    "    df_return['err2'] = err2\n",
    "    df_return['detected'] = detected\n",
    "    \n",
    "    return df_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Changing Params Here\n",
    "def trainning(train_data, train_label,f,params):\n",
    "    result=[]\n",
    "    pred=[]\n",
    "    for i in range(4):\n",
    "        train_set=[]\n",
    "        train_set_label=[]\n",
    "        test_folder=i\n",
    "        for j in range(4):\n",
    "            if j!=i:\n",
    "                train_set.append(train_data[j])\n",
    "                train_set_label.append(train_label[j])\n",
    "        model=trainLSTM(train_set, train_set_label, params[0],params[1])\n",
    "        df_manual=toPanda_train(train_label,test_folder,f)\n",
    "        df_pred=toPanda_test(model,train_data,test_folder,f)\n",
    "        df_results = score_periods(df_manual, df_pred)\n",
    "        pred.append(df_pred)\n",
    "        result.append(df_results)\n",
    "    return result,pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "13494/13494 [==============================] - 6s 438us/step - loss: 0.4916 - acc: 0.8962\n",
      "Epoch 2/10\n",
      "13494/13494 [==============================] - 4s 306us/step - loss: 0.3960 - acc: 0.8996\n",
      "Epoch 3/10\n",
      "13494/13494 [==============================] - 4s 319us/step - loss: 0.4031 - acc: 0.9005\n",
      "Epoch 4/10\n",
      "13494/13494 [==============================] - 4s 329us/step - loss: 0.3729 - acc: 0.9065\n",
      "Epoch 5/10\n",
      "13494/13494 [==============================] - 4s 322us/step - loss: 0.3657 - acc: 0.9094\n",
      "Epoch 6/10\n",
      "13494/13494 [==============================] - 4s 310us/step - loss: 0.3641 - acc: 0.9086\n",
      "Epoch 7/10\n",
      "13494/13494 [==============================] - 4s 295us/step - loss: 0.3616 - acc: 0.9117\n",
      "Epoch 8/10\n",
      "13494/13494 [==============================] - 4s 304us/step - loss: 0.3696 - acc: 0.9086\n",
      "Epoch 9/10\n",
      "13494/13494 [==============================] - 4s 308us/step - loss: 0.3554 - acc: 0.9131\n",
      "Epoch 10/10\n",
      "13494/13494 [==============================] - 4s 323us/step - loss: 0.3498 - acc: 0.9133\n",
      "Epoch 1/10\n",
      "13495/13495 [==============================] - 4s 329us/step - loss: 0.6001 - acc: 0.8282\n",
      "Epoch 2/10\n",
      "13495/13495 [==============================] - 4s 299us/step - loss: 0.6385 - acc: 0.7952\n",
      "Epoch 3/10\n",
      "13495/13495 [==============================] - 4s 294us/step - loss: 0.7321 - acc: 0.7936\n",
      "Epoch 4/10\n",
      "13495/13495 [==============================] - 4s 313us/step - loss: 0.6652 - acc: 0.8030\n",
      "Epoch 5/10\n",
      "13495/13495 [==============================] - 4s 300us/step - loss: 0.7494 - acc: 0.7740\n",
      "Epoch 6/10\n",
      "13495/13495 [==============================] - 4s 304us/step - loss: 0.7394 - acc: 0.8046\n",
      "Epoch 7/10\n",
      "13495/13495 [==============================] - 4s 310us/step - loss: 0.6830 - acc: 0.8133\n",
      "Epoch 8/10\n",
      "13495/13495 [==============================] - 4s 307us/step - loss: 0.6657 - acc: 0.8176\n",
      "Epoch 9/10\n",
      "13495/13495 [==============================] - 4s 303us/step - loss: 0.6565 - acc: 0.8166\n",
      "Epoch 10/10\n",
      "13495/13495 [==============================] - 4s 324us/step - loss: 0.6594 - acc: 0.8144\n",
      "Epoch 1/10\n",
      "13497/13497 [==============================] - 4s 315us/step - loss: 0.8311 - acc: 0.7257\n",
      "Epoch 2/10\n",
      "13497/13497 [==============================] - 4s 313us/step - loss: 0.7180 - acc: 0.7602\n",
      "Epoch 3/10\n",
      "13497/13497 [==============================] - 4s 311us/step - loss: 0.6615 - acc: 0.7791\n",
      "Epoch 4/10\n",
      "13497/13497 [==============================] - 4s 320us/step - loss: 0.6333 - acc: 0.7886\n",
      "Epoch 5/10\n",
      "13497/13497 [==============================] - 4s 308us/step - loss: 0.6171 - acc: 0.7940\n",
      "Epoch 6/10\n",
      "13497/13497 [==============================] - 4s 317us/step - loss: 0.6122 - acc: 0.7930\n",
      "Epoch 7/10\n",
      "13497/13497 [==============================] - 4s 305us/step - loss: 0.6072 - acc: 0.7965\n",
      "Epoch 8/10\n",
      "13497/13497 [==============================] - 4s 301us/step - loss: 0.5978 - acc: 0.7968\n",
      "Epoch 9/10\n",
      "13497/13497 [==============================] - 4s 309us/step - loss: 0.5945 - acc: 0.8001\n",
      "Epoch 10/10\n",
      "13497/13497 [==============================] - 4s 316us/step - loss: 0.5971 - acc: 0.7955\n",
      "Epoch 1/10\n",
      "13494/13494 [==============================] - 6s 428us/step - loss: 0.8834 - acc: 0.7320\n",
      "Epoch 2/10\n",
      "13494/13494 [==============================] - 4s 306us/step - loss: 0.7962 - acc: 0.7486\n",
      "Epoch 3/10\n",
      "13494/13494 [==============================] - 4s 292us/step - loss: 0.7955 - acc: 0.7515\n",
      "Epoch 4/10\n",
      "13494/13494 [==============================] - 4s 314us/step - loss: 0.7792 - acc: 0.7568\n",
      "Epoch 5/10\n",
      "13494/13494 [==============================] - 4s 323us/step - loss: 0.7768 - acc: 0.7575 0s - loss: 0.7756 - acc: 0.757\n",
      "Epoch 6/10\n",
      "13494/13494 [==============================] - 4s 298us/step - loss: 0.7775 - acc: 0.7557\n",
      "Epoch 7/10\n",
      "13494/13494 [==============================] - 4s 314us/step - loss: 0.7728 - acc: 0.7571\n",
      "Epoch 8/10\n",
      "13494/13494 [==============================] - 4s 306us/step - loss: 0.7713 - acc: 0.7572\n",
      "Epoch 9/10\n",
      "13494/13494 [==============================] - 4s 305us/step - loss: 0.7716 - acc: 0.7580\n",
      "Epoch 10/10\n",
      "13494/13494 [==============================] - 4s 306us/step - loss: 0.7950 - acc: 0.7559\n",
      "Epoch 1/10\n",
      "13495/13495 [==============================] - 4s 309us/step - loss: 0.6516 - acc: 0.8061\n",
      "Epoch 2/10\n",
      "13495/13495 [==============================] - 4s 304us/step - loss: 0.6363 - acc: 0.8105\n",
      "Epoch 3/10\n",
      "13495/13495 [==============================] - 4s 305us/step - loss: 0.6328 - acc: 0.8083\n",
      "Epoch 4/10\n",
      "13495/13495 [==============================] - 4s 305us/step - loss: 0.6248 - acc: 0.8105\n",
      "Epoch 5/10\n",
      "13495/13495 [==============================] - 4s 312us/step - loss: 0.6223 - acc: 0.8119\n",
      "Epoch 6/10\n",
      "13495/13495 [==============================] - 5s 347us/step - loss: 0.6225 - acc: 0.8097\n",
      "Epoch 7/10\n",
      "13495/13495 [==============================] - 4s 325us/step - loss: 0.6520 - acc: 0.7931\n",
      "Epoch 8/10\n",
      "13495/13495 [==============================] - 4s 294us/step - loss: 0.6175 - acc: 0.8142\n",
      "Epoch 9/10\n",
      "13495/13495 [==============================] - 4s 301us/step - loss: 0.6227 - acc: 0.8146\n",
      "Epoch 10/10\n",
      "13495/13495 [==============================] - 4s 292us/step - loss: 0.6151 - acc: 0.8193\n",
      "Epoch 1/10\n",
      "13497/13497 [==============================] - 4s 310us/step - loss: 0.8145 - acc: 0.7224\n",
      "Epoch 2/10\n",
      "13497/13497 [==============================] - 4s 295us/step - loss: 0.7512 - acc: 0.7574\n",
      "Epoch 3/10\n",
      "13497/13497 [==============================] - 4s 304us/step - loss: 0.7065 - acc: 0.7660\n",
      "Epoch 4/10\n",
      "13497/13497 [==============================] - 4s 300us/step - loss: 0.6763 - acc: 0.7742\n",
      "Epoch 5/10\n",
      "13497/13497 [==============================] - 4s 304us/step - loss: 0.6989 - acc: 0.7731\n",
      "Epoch 6/10\n",
      "13497/13497 [==============================] - 4s 290us/step - loss: 0.6739 - acc: 0.7758\n",
      "Epoch 7/10\n",
      "13497/13497 [==============================] - 4s 314us/step - loss: 0.6599 - acc: 0.7825\n",
      "Epoch 8/10\n",
      "13497/13497 [==============================] - 4s 304us/step - loss: 0.6600 - acc: 0.7766\n",
      "Epoch 9/10\n",
      "13497/13497 [==============================] - 4s 295us/step - loss: 0.6547 - acc: 0.7820\n",
      "Epoch 10/10\n",
      "13497/13497 [==============================] - 4s 317us/step - loss: 0.6379 - acc: 0.7830\n",
      "Epoch 1/10\n",
      "13494/13494 [==============================] - 6s 449us/step - loss: 0.8523 - acc: 0.7386\n",
      "Epoch 2/10\n",
      "13494/13494 [==============================] - 4s 312us/step - loss: 0.7836 - acc: 0.7481\n",
      "Epoch 3/10\n",
      "13494/13494 [==============================] - 4s 304us/step - loss: 0.7684 - acc: 0.7578\n",
      "Epoch 4/10\n",
      "13494/13494 [==============================] - 4s 314us/step - loss: 0.7613 - acc: 0.7610\n",
      "Epoch 5/10\n",
      "13494/13494 [==============================] - 4s 322us/step - loss: 0.7538 - acc: 0.7625\n",
      "Epoch 6/10\n",
      "13494/13494 [==============================] - 4s 310us/step - loss: 0.7476 - acc: 0.7661\n",
      "Epoch 7/10\n",
      "13494/13494 [==============================] - 4s 298us/step - loss: 0.7465 - acc: 0.7657\n",
      "Epoch 8/10\n",
      "13494/13494 [==============================] - 4s 296us/step - loss: 0.7537 - acc: 0.7676\n",
      "Epoch 9/10\n",
      "13494/13494 [==============================] - 4s 325us/step - loss: 0.7527 - acc: 0.7660\n",
      "Epoch 10/10\n",
      "13494/13494 [==============================] - 4s 291us/step - loss: 0.7465 - acc: 0.7680\n",
      "Epoch 1/10\n",
      "13494/13494 [==============================] - 4s 301us/step - loss: 0.3806 - acc: 0.9097\n",
      "Epoch 2/10\n",
      "13494/13494 [==============================] - 4s 294us/step - loss: 0.3766 - acc: 0.9094\n",
      "Epoch 3/10\n",
      "13494/13494 [==============================] - 4s 307us/step - loss: 0.3686 - acc: 0.9086\n",
      "Epoch 4/10\n",
      "13494/13494 [==============================] - 4s 293us/step - loss: 0.3743 - acc: 0.9092\n",
      "Epoch 5/10\n",
      "13494/13494 [==============================] - 4s 322us/step - loss: 0.3741 - acc: 0.9066\n",
      "Epoch 6/10\n",
      "13494/13494 [==============================] - 4s 314us/step - loss: 0.3679 - acc: 0.9076\n",
      "Epoch 7/10\n",
      "13494/13494 [==============================] - 4s 307us/step - loss: 0.3746 - acc: 0.9088\n",
      "Epoch 8/10\n",
      "13494/13494 [==============================] - 4s 320us/step - loss: 0.3670 - acc: 0.9082\n",
      "Epoch 9/10\n",
      "13494/13494 [==============================] - 4s 321us/step - loss: 0.3675 - acc: 0.9081\n",
      "Epoch 10/10\n",
      "13494/13494 [==============================] - 4s 293us/step - loss: 0.3603 - acc: 0.9083\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13497/13497 [==============================] - 4s 317us/step - loss: 0.8338 - acc: 0.7243\n",
      "Epoch 2/10\n",
      "13497/13497 [==============================] - 4s 300us/step - loss: 0.6995 - acc: 0.7714\n",
      "Epoch 3/10\n",
      "13497/13497 [==============================] - 4s 315us/step - loss: 0.6797 - acc: 0.7741\n",
      "Epoch 4/10\n",
      "13497/13497 [==============================] - 4s 305us/step - loss: 0.6626 - acc: 0.7771\n",
      "Epoch 5/10\n",
      "13497/13497 [==============================] - 4s 311us/step - loss: 0.6472 - acc: 0.7841\n",
      "Epoch 6/10\n",
      "13497/13497 [==============================] - 4s 307us/step - loss: 0.6341 - acc: 0.7843\n",
      "Epoch 7/10\n",
      "13497/13497 [==============================] - 4s 322us/step - loss: 0.6345 - acc: 0.7854\n",
      "Epoch 8/10\n",
      "13050/13497 [============================>.] - ETA: 0s - loss: 0.6255 - acc: 0.7875Epoch 1/10\n",
      "13494/13494 [==============================] - 5s 402us/step - loss: 0.8760 - acc: 0.7304\n",
      "Epoch 2/10\n",
      "13494/13494 [==============================] - 4s 325us/step - loss: 0.8153 - acc: 0.7446\n",
      "Epoch 3/10\n",
      "13494/13494 [==============================] - 4s 314us/step - loss: 0.7918 - acc: 0.7472\n",
      "Epoch 4/10\n",
      "13494/13494 [==============================] - 4s 283us/step - loss: 0.7851 - acc: 0.7500\n",
      "Epoch 5/10\n",
      "13494/13494 [==============================] - 4s 320us/step - loss: 0.7784 - acc: 0.7534\n",
      "Epoch 6/10\n",
      "13494/13494 [==============================] - 4s 296us/step - loss: 0.7810 - acc: 0.7534\n",
      "Epoch 7/10\n",
      "13494/13494 [==============================] - 4s 324us/step - loss: 0.7726 - acc: 0.7544\n",
      "Epoch 8/10\n",
      "13494/13494 [==============================] - 4s 299us/step - loss: 0.7663 - acc: 0.7574\n",
      "Epoch 9/10\n",
      "13494/13494 [==============================] - 4s 321us/step - loss: 0.7679 - acc: 0.7576\n",
      "Epoch 10/10\n",
      "13494/13494 [==============================] - 4s 317us/step - loss: 0.7889 - acc: 0.7612\n",
      "Epoch 1/10\n",
      "13494/13494 [==============================] - 4s 332us/step - loss: 0.3847 - acc: 0.9073\n",
      "Epoch 2/10\n",
      "13494/13494 [==============================] - 4s 302us/step - loss: 0.3661 - acc: 0.9086\n",
      "Epoch 3/10\n",
      "13494/13494 [==============================] - 4s 315us/step - loss: 0.3546 - acc: 0.9092\n",
      "Epoch 4/10\n",
      "13494/13494 [==============================] - 4s 332us/step - loss: 0.3482 - acc: 0.9080\n",
      "Epoch 5/10\n",
      "13494/13494 [==============================] - 5s 334us/step - loss: 0.3487 - acc: 0.9099\n",
      "Epoch 6/10\n",
      "13494/13494 [==============================] - 4s 292us/step - loss: 0.3466 - acc: 0.9094\n",
      "Epoch 7/10\n",
      "13494/13494 [==============================] - 4s 300us/step - loss: 0.3437 - acc: 0.9112\n",
      "Epoch 8/10\n",
      "13494/13494 [==============================] - 4s 318us/step - loss: 0.3409 - acc: 0.9110\n",
      "Epoch 9/10\n",
      "13494/13494 [==============================] - 4s 301us/step - loss: 0.3412 - acc: 0.9106\n",
      "Epoch 10/10\n",
      "13494/13494 [==============================] - 4s 294us/step - loss: 0.3455 - acc: 0.9097\n",
      "Epoch 1/10\n",
      "13495/13495 [==============================] - 4s 321us/step - loss: 0.6320 - acc: 0.8084\n",
      "Epoch 2/10\n",
      "13495/13495 [==============================] - 4s 316us/step - loss: 0.6250 - acc: 0.8196\n",
      "Epoch 3/10\n",
      "13495/13495 [==============================] - 4s 315us/step - loss: 0.6087 - acc: 0.8247\n",
      "Epoch 4/10\n",
      "13495/13495 [==============================] - 4s 307us/step - loss: 0.6042 - acc: 0.8256\n",
      "Epoch 5/10\n",
      "13495/13495 [==============================] - 4s 303us/step - loss: 0.5970 - acc: 0.8256\n",
      "Epoch 6/10\n",
      "13495/13495 [==============================] - 4s 329us/step - loss: 0.5916 - acc: 0.8274\n",
      "Epoch 7/10\n",
      "13495/13495 [==============================] - 5s 337us/step - loss: 0.6163 - acc: 0.8191\n",
      "Epoch 8/10\n",
      "13495/13495 [==============================] - 4s 329us/step - loss: 0.6125 - acc: 0.8224\n",
      "Epoch 9/10\n",
      "13495/13495 [==============================] - 4s 296us/step - loss: 0.6164 - acc: 0.8201\n",
      "Epoch 10/10\n",
      "13495/13495 [==============================] - 4s 316us/step - loss: 0.6059 - acc: 0.8202\n"
     ]
    }
   ],
   "source": [
    "params=[64,15]\n",
    "result,pred=trainning(train_data,train_label,f,params)\n",
    "man=[]\n",
    "for i in range(4):\n",
    "    man.append(toPanda_train(train_label,i,f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 10)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "folder=1\n",
    "df_pred=pred[folder]\n",
    "df_manual=man[folder]\n",
    "kT=f[folder]['color']['kT'][0]\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.collections import PatchCollection\n",
    "a=[0,0]\n",
    "b=[0,5]\n",
    "c=[7,0]\n",
    "d=[7,5]\n",
    "width = c[0] - a[0]\n",
    "height = d[1] - a[1]\n",
    "lims = (0, 10)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "%matplotlib inline\n",
    "\n",
    "fig1 = plt.figure()\n",
    "ax1 = fig1.add_subplot(111, aspect='equal')\n",
    "ax1.add_patch(\n",
    "    patches.Rectangle((0, 0), width, height))\n",
    "ax1.add_patch(\n",
    "    patches.Rectangle((1, 1), width, height))\n",
    "plt.ylim(lims)\n",
    "plt.xlim(lims)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label         offset          onset        err1        err2  detected\n",
      "0      l  431774.517403  431772.851481 -129.465501 -135.199552     False\n",
      "1      l  431793.651407  431791.784340 -110.532642 -116.065548     False\n",
      "2      r  431911.983951  431902.183981   -0.133001    2.266997      True\n",
      "3      l  431906.851042  431903.916978    1.599996   -2.865913      True\n",
      "4      r  431952.050903  431946.383842   -0.133011    4.799991      True\n",
      "5      l  432011.183628  432003.716717         NaN         NaN     False\n",
      "6      r  432011.050703  432004.183651         NaN         NaN     False\n",
      "7      r  432020.650674  432014.383617    6.399978   12.399957     False\n",
      "8      r  432070.383439  432068.383440   60.399801   62.132722     False\n",
      "9      r  432080.183408  432073.916494   65.932854   71.932691     False\n",
      "10     r  432190.050130  432183.716137         NaN         NaN     False\n",
      "11     l  432190.183049  432185.183064         NaN         NaN     False\n",
      "12     r  432215.916041  432213.382975   27.199911   28.799908     False\n",
      "13     r  432225.050138  432224.050141   37.867077   37.934005     False\n",
      "14     r  432356.515577  432354.915585  -52.866764  -64.333732     False\n",
      "15     l  432433.382341  432407.382350   -0.399999   12.533032     False\n",
      "16     r  432422.715362  432408.315411    0.533062    1.866052      True\n",
      "17     l  432523.715037  432516.248996         NaN         NaN     False\n",
      "18     l  432602.781791  432598.448728   76.599750   80.866750     False\n",
      "19     r  432602.714781  432599.581804   77.732825   80.799740     False\n"
     ]
    }
   ],
   "source": [
    "pred[0].to_pickle('df_pred1.dat')\n",
    "pred[1].to_pickle('df_pred2.dat')\n",
    "pred[2].to_pickle('df_pred3.dat')\n",
    "pred[3].to_pickle('df_pred4.dat')\n",
    "a=pd.read_pickle('df_pred1.dat')\n",
    "print(result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.0\n",
      "20\n",
      "Confusion matrix, without normalization\n",
      "[[20  0]\n",
      " [ 4  0]]\n",
      "MSE1: 8482.99661532 [s], MSE: 9121.94570157 [s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nathan/anaconda2/envs/tensorflow/lib/python2.7/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n",
      "/home/nathan/anaconda2/envs/tensorflow/lib/python2.7/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%% Summarize results\n",
    "# declare variables\n",
    "folder=1\n",
    "df_pred=pred[folder]\n",
    "df_man=man[folder]\n",
    "df_result=result[folder]\n",
    "N_pred = float(len(df_pred))\n",
    "N_man = float(len(df_manual))\n",
    "print(N_man)\n",
    "TP = np.sum(df_results['detected'])\n",
    "print(TP)\n",
    "FP = N_pred - TP\n",
    "TN = 0\n",
    "FN = N_man - TP\n",
    "\n",
    "cm = np.array([[TP, FP], [FN, TN]], dtype='int').T\n",
    "\n",
    "plot_confusion_matrix(cm, ('', ''))\n",
    "\n",
    "#%% Plot distributions of error\n",
    "\n",
    "sns.distplot(df_results['err1'].dropna())\n",
    "sns.distplot(df_results['err2'].dropna())\n",
    "\n",
    "#%% Calculate MSE\n",
    "MSE1 = df_results['err1'].dropna().mean() + df_results['err1'].dropna().std()**2\n",
    "MSE2 = df_results['err2'].dropna().mean() + df_results['err2'].dropna().std()**2\n",
    "\n",
    "print \"MSE1: {0} [s], MSE: {1} [s]\".format(MSE1, MSE2)\n",
    "\n",
    "#%% TP / N_man\n",
    "rateP = TP / N_man\n",
    "ratioP = N_pred / N_man\n",
    "\n",
    "print rateP, ratioP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri May 25 10:35:58 2018\n",
    "\n",
    "@author: Paolo Gabriel\n",
    "\"\"\"\n",
    "#%%\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Arc\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "#  === Angle functions ===\n",
    "\n",
    "def unit_vector(vector):\n",
    "    \"\"\" Returns the unit vector of the vector.  \"\"\"\n",
    "    return vector / np.linalg.norm(vector)\n",
    "\n",
    "def angle_between(v1, v2, deg=True):\n",
    "    \"\"\" Returns the anti-clockwise angle in degrees between vectors 'v1' and 'v2'::\n",
    "\n",
    "            >>> angle_between((1, 0, 0), (0, 1, 0))\n",
    "            1.5707963267948966\n",
    "            >>> angle_between((1, 0, 0), (1, 0, 0))\n",
    "            0.0\n",
    "            >>> angle_between((1, 0, 0), (-1, 0, 0))\n",
    "            3.141592653589793\n",
    "    \"\"\"\n",
    "\n",
    "    def inner_angle(v, w):\n",
    "        cross = np.cross(v, w)\n",
    "        cosang = np.dot(v, w)\n",
    "        sinang = np.linalg.norm(cross)\n",
    "        return np.arctan2(sinang, cosang)\n",
    "    \n",
    "    def determinant(v,w):\n",
    "        return v[0]*w[1]-v[1]*w[0]\n",
    "    \n",
    "    v1_u = unit_vector(v1)\n",
    "    v2_u = unit_vector(v2)\n",
    "    \n",
    "    angle = inner_angle(v1_u, v2_u)\n",
    "    det = determinant(v1_u, v2_u)\n",
    "    \n",
    "    if det < 0: angle = 2*np.pi - angle\n",
    "\n",
    "    if deg: angle = angle * 180/np.pi\n",
    "    \n",
    "    return angle\n",
    "\n",
    "def get_axillary_angle(base, rotator):\n",
    "    \"\"\" Returns the shoulder angle in degrees between vectors 'base' (static) and 'rotator' after checking the direction of 'base'::\n",
    "\n",
    "    \"\"\"\n",
    "    if base[0] > 0:\n",
    "        return angle_between(rotator, base)\n",
    "    else:\n",
    "        return angle_between(base, rotator)\n",
    "    \n",
    "def get_elbow_angle(base, rotator):\n",
    "    \"\"\" Returns the elbow angle in degrees between vectors 'base' (static) and 'rotator'::\n",
    "\n",
    "    \"\"\"\n",
    "    return min(angle_between(rotator, base), angle_between(base, rotator))\n",
    "# == / Angle functions / ==\n",
    "\n",
    "# == Extra functions ==\n",
    "def gen_rand_vecs(dims, number):\n",
    "    vecs = np.random.normal(size=(number,dims))\n",
    "    mags = np.linalg.norm(vecs, axis=-1)\n",
    "\n",
    "    return vecs / mags[..., np.newaxis]\n",
    "\n",
    "def plot_angles(ax, base, rotator):\n",
    "    angle1 = angle_between((1,0), base) \n",
    "    angle2 = angle_between((1,0), rotator)\n",
    "    \n",
    "    l1 = mlines.Line2D([0,base[0]], [0, base[1]], color='k')\n",
    "    l2 = mlines.Line2D([0,rotator[0]], [0, rotator[1]], color='b')\n",
    "    \n",
    "    return l1, l2, angle1, angle2\n",
    "\n",
    "# NOTE: plot_arcs is bugged! \n",
    "#   Angles calculated are correct, but the way to plot arcs requires some logic \n",
    "#   regarding the relationship between v1 and v2\n",
    "def plot_arcs(ax, v1, v2, offset1, offset2):\n",
    "    theta1 = get_elbow_angle(v1, v2)\n",
    "    theta2 = get_axillary_angle(v1, v2)\n",
    "    \n",
    "    if offset2 - offset1 > 180:\n",
    "        e_offset = max(offset1, offset2)\n",
    "    else:        \n",
    "        e_offset = min(offset1, offset2)\n",
    "    \n",
    "    if offset2 - offset1 < theta2:\n",
    "        a_offset = max(offset1, offset2)\n",
    "    else:\n",
    "        a_offset = min(offset1, offset2)\n",
    "\n",
    "    arc1 = Arc([0,0], 0.5, 0.5, angle=0, theta1=e_offset, theta2=e_offset+theta1, color='g')\n",
    "    arc2 = Arc([0,0], 0.75, 0.75, angle=0, theta1=a_offset, theta2=a_offset+theta2, color='r')\n",
    "\n",
    "    \n",
    "    return arc1, arc2, theta1, theta2\n",
    "\n",
    "def run_demo():\n",
    "    plt.close('all')\n",
    "    # generate simulated data\n",
    "    v1 = np.array((-1, 0)) # simulation of RS -> LS (shoulder to shoulder) vector\n",
    "    v2s = ((1,0), (1,1), (0,1), (-1,1), (-1,0) , (-1,-1), (0, -1), (1,-1)) # simulation of fixed angles of RS->RE (shoulder to elbow)\n",
    "    \n",
    "    # plot simulated data\n",
    "    for i, v2 in enumerate(v2s):\n",
    "        fig, ax = plt.subplots(1)\n",
    "        \n",
    "        l1, l2, offset1, offset2 = plot_angles(ax, v1, v2)\n",
    "        arc1, arc2, theta1, theta2 = plot_arcs(ax, v1, v2, offset1, offset2)\n",
    "                \n",
    "        ax.add_patch(arc1)\n",
    "        ax.add_patch(arc2)\n",
    "        ax.add_line(l1)\n",
    "        ax.add_line(l2)\n",
    "    \n",
    "        ax.legend(('Base', 'Rotator', 'elbow angle = {0} deg'.format(theta1), 'shoulder angle = {0} deg'.format(theta2)))\n",
    "    \n",
    "        ax.set_xlim(-1.5, 1.5)\n",
    "        ax.set_ylim(-1.5, 1.5)    \n",
    "        ax.set_aspect('equal')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "run_demo()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
